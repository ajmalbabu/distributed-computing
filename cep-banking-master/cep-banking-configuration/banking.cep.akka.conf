# This file provides a set of AKKA configuration for application.
akka {

  loggers = ["akka.event.slf4j.Slf4jLogger"]
  loglevel = "info"
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"

  actor {

    provider = "akka.cluster.ClusterActorRefProvider"
    deployment {
      # Use a wild dispatcher to take care for any actor.
      "/*" {
        router = round-robin-pool
        # Don't change below to anything higher than 1. For such needs duplicate another one with actor name as shown below.
        nr-of-instances = 1
      }
      /randomGeneratorActor {
        router = round-robin-pool
        nr-of-instances = 5
      }
      /responseHandlerActor {
        router = round-robin-pool
        nr-of-instances = 5
      }
      /garbageCollectionAgent {
        router = round-robin-pool
        nr-of-instances = 5
      }
    }
  }

  cluster.sharding {
    remember-entities = on
    journal-plugin-id = "cassandra-journal"
    snapshot-plugin-id = "cassandra-snapshot-store"

  }

  remote {
    log-remote-lifecycle-events = off
    netty.tcp {
      hostname = ${node.host}
      port = ${node.port}
    }
  }


  extensions = ["akka.persistence.Persistence"]

  cluster {
    seed-nodes = [${node.seed-nodes1}, ${node.seed-nodes2}]
    auto-down-unreachable-after = 10s
    //    min-nr-of-members = 2
    //    allow-weakly-up-members = on
    metrics.enabled = off

  }

  # Change to cassandra for non dev. environement such as qa & production. Or to test the cluster sharding.

  persistence {
    journal {
      plugin = "cassandra-journal"
      cassandra-journal.contact-points = ["127.0.0.1"]
      auto-start-journals = ["cassandra-journal"]
    }

    snapshot-store {
      plugin = "cassandra-snapshot-store"
      cassandra-snapshot-store.contact-points = ["127.0.0.1"]
      auto-start-snapshot-stores = ["cassandra-snapshot-store"]
    }
  }

  # Level DB is goood for laptop based development.

  //  persistence {
  //    journal {
  //      plugin = "akka.persistence.journal.leveldb"
  //      leveldb {
  //        dir = "target/example/journal"
  //        native = false
  //      }
  //    }
  //    snapshot-store {
  //      plugin = "akka.persistence.snapshot-store.local"
  //      local.dir = "target/example/snapshots"
  //    }
  //  }
}

# Use Chef scripts to change IP, port, actor system name, seed nodes during deployment time for each env. in here.

node {
  host = "127.0.0.1"
  port = 2551
  seed-nodes1 = "akka.tcp://BankingCepActorSystem@127.0.0.1:2551"
  seed-nodes2 = "akka.tcp://BankingCepActorSystem@127.0.0.1:2552"
}

akka.log-config-on-start = false

akka.cluster.sharding.remember-entities = on

# Define the dispatcher for whole actor system, which points to default thread-pool-exector.
# This definition does not refer to dispatcher that is defined for task runner dispatcher just below
# rather it points to the  default thread-pool-dispachter available within AKKA default configuration.
# https://github.com/akka/akka/blob/v2.4.1/akka-actor/src/main/resources/reference.conf#L332
akka.actor.default-dispatcher.default-executor.fallback = "thread-pool-executor"

# This dispatcher is being refered by Cep Service when it creates actors.
task-runner-actor-dispatcher {

  # Dispatcher is the name of the event-based dispatcher
  type = Dispatcher

  # What kind of ExecutionService to use
  executor = "thread-pool-executor"

  # This will be used if you have set "executor = "thread-pool-executor""
  thread-pool-executor {

    # Keep alive time for threads
    keep-alive-time = 60s

    # Min number of threads to cap factor-based core number to
    core-pool-size-min = 8

    # The core pool size factor is used to determine thread pool core size
    # using the following formula: ceil(available processors * factor).
    # Resulting size is then bounded by the core-pool-size-min and
    # core-pool-size-max values.
    core-pool-size-factor = 3.0

    # Max number of threads to cap factor-based number to
    core-pool-size-max = 64

    # Minimum number of threads to cap factor-based max number to
    # (if using a bounded task queue)
    max-pool-size-min = 8

    # Max no of threads (if using a bounded task queue) is determined by
    # calculating: ceil(available processors * factor)
    max-pool-size-factor = 3.0

    # Max number of threads to cap factor-based max number to
    # (if using a  bounded task queue)
    max-pool-size-max = 64

    # Specifies the bounded capacity of the task queue (< 1 == unbounded)
    task-queue-size = -1

    # Specifies which type of task queue will be used, can be "array" or
    # "linked" (default)
    task-queue-type = "linked"

    # Allow core threads to time out
    allow-core-timeout = on
  }

  # Throughput defines the maximum number of messages to be
  # processed per actor before the thread jumps to the next actor.
  # Set to 1 for as fair as possible.
  throughput = 1
}


